{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title Fake News Detection - Final Working Version\n",
        "# Step 1: Install and import everything first\n",
        "!pip install pandas numpy nltk scikit-learn tensorflow --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "# Step 2: Download ALL required NLTK data first\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)  # This fixes the specific error\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"âœ… All packages installed and ready!\")\n",
        "\n",
        "# Step 3: Create better sample dataset\n",
        "print(\"\\nğŸ“Š Creating enhanced dataset...\")\n",
        "data = {\n",
        "    'text': [\n",
        "        \"NASA confirms climate change is accelerating due to human activity\",\n",
        "        \"Aliens built the pyramids and live inside Earth\",\n",
        "        \"Regular exercise improves mental health, says new study\",\n",
        "        \"5G towers spread COVID-19 virus, doctors confirm\",\n",
        "        \"Vaccines are safe and effective, WHO reports\",\n",
        "        \"Bill Gates implants microchips through vaccines\",\n",
        "        \"Scientists agree that global warming is real\",\n",
        "        \"The government is hiding evidence of UFOs\",\n",
        "        \"Eating vegetables improves longevity\",\n",
        "        \"Moon is made of cheese, astronauts confirm\"\n",
        "    ],\n",
        "    'label': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]  # 0 = Real, 1 = Fake\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(\"\\nSample Dataset (First 5 entries):\")\n",
        "print(df.head())\n",
        "\n",
        "# Step 4: Improved text cleaning\n",
        "print(\"\\nğŸ§¹ Cleaning text data...\")\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    try:\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  # URLs\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)  # Punctuation\n",
        "        text = re.sub(r'\\d+', '', text)  # Numbers\n",
        "        words = nltk.word_tokenize(text)\n",
        "        words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words and len(word) > 2]\n",
        "        return ' '.join(words)\n",
        "    except Exception as e:\n",
        "        print(f\"Error cleaning text: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "df['cleaned_text'] = df['text'].apply(clean_text)\n",
        "print(\"\\nBefore and after cleaning example:\")\n",
        "print(\"Original:\", df['text'][0])\n",
        "print(\"Cleaned:\", df['cleaned_text'][0])\n",
        "\n",
        "# Step 5: Prepare ML data\n",
        "print(\"\\nğŸ”¢ Converting text to numbers...\")\n",
        "tfidf = TfidfVectorizer(max_features=1000)\n",
        "X = tfidf.fit_transform(df['cleaned_text'])\n",
        "y = df['label']\n",
        "\n",
        "# Better train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Step 6: Train model\n",
        "print(\"\\nğŸ¤– Training the model...\")\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nğŸ¯ Model Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "# Step 7: Prediction function with error handling\n",
        "def predict_news(news_text):\n",
        "    try:\n",
        "        cleaned = clean_text(news_text)\n",
        "        if not cleaned.strip():  # Check for empty string after cleaning\n",
        "            print(\"âš ï¸ Text couldn't be properly processed\")\n",
        "            return\n",
        "\n",
        "        vector = tfidf.transform([cleaned])\n",
        "        prediction = model.predict(vector)[0]\n",
        "        confidence = model.predict_proba(vector)[0].max()\n",
        "\n",
        "        result = \"ğŸ”´ FAKE NEWS\" if prediction == 1 else \"ğŸŸ¢ REAL NEWS\"\n",
        "        print(f\"\\nğŸ“ Your Text: {news_text}\")\n",
        "        print(f\"ğŸ§¼ Cleaned Version: {cleaned}\")\n",
        "        print(f\"\\nğŸ” Prediction: {result} (Confidence: {confidence*100:.1f}%)\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error: {e}\")\n",
        "\n",
        "# Test examples\n",
        "print(\"\\nğŸ§ª Testing the model with sample news:\")\n",
        "test_examples = [\n",
        "    \"The Earth is flat according to new research\",\n",
        "    \"COVID-19 vaccines have been approved by health authorities worldwide\",\n",
        "    \"Drinking bleach cures coronavirus\",\n",
        "    \"Climate change is causing more extreme weather events\",\n",
        "    \"The moon landing was filmed in a Hollywood studio\"\n",
        "]\n",
        "\n",
        "for example in test_examples:\n",
        "    predict_news(example)\n",
        "    print(\"â”\"*50)\n",
        "\n",
        "print(\"\\nâœ¨ Try your own news! Run: predict_news('Your news text here')\")\n",
        "print(\"Example: predict_news('Some breaking news story')\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioO2r3P1892m",
        "outputId": "ba72da1b-a73b-4e40-ac13-63287fb0575f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All packages installed and ready!\n",
            "\n",
            "ğŸ“Š Creating enhanced dataset...\n",
            "\n",
            "Sample Dataset (First 5 entries):\n",
            "                                                text  label\n",
            "0  NASA confirms climate change is accelerating d...      0\n",
            "1    Aliens built the pyramids and live inside Earth      1\n",
            "2  Regular exercise improves mental health, says ...      0\n",
            "3   5G towers spread COVID-19 virus, doctors confirm      1\n",
            "4       Vaccines are safe and effective, WHO reports      0\n",
            "\n",
            "ğŸ§¹ Cleaning text data...\n",
            "\n",
            "Before and after cleaning example:\n",
            "Original: NASA confirms climate change is accelerating due to human activity\n",
            "Cleaned: nasa confirms climate change accelerating due human activity\n",
            "\n",
            "ğŸ”¢ Converting text to numbers...\n",
            "\n",
            "ğŸ¤– Training the model...\n",
            "\n",
            "ğŸ¯ Model Accuracy: 33.33%\n",
            "\n",
            "ğŸ§ª Testing the model with sample news:\n",
            "\n",
            "ğŸ“ Your Text: The Earth is flat according to new research\n",
            "ğŸ§¼ Cleaned Version: earth flat according new research\n",
            "\n",
            "ğŸ” Prediction: ğŸŸ¢ REAL NEWS (Confidence: 60.6%)\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "\n",
            "ğŸ“ Your Text: COVID-19 vaccines have been approved by health authorities worldwide\n",
            "ğŸ§¼ Cleaned Version: covid vaccine approved health authority worldwide\n",
            "\n",
            "ğŸ” Prediction: ğŸŸ¢ REAL NEWS (Confidence: 58.9%)\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "\n",
            "ğŸ“ Your Text: Drinking bleach cures coronavirus\n",
            "ğŸ§¼ Cleaned Version: drinking bleach cure coronavirus\n",
            "\n",
            "ğŸ” Prediction: ğŸŸ¢ REAL NEWS (Confidence: 57.1%)\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "\n",
            "ğŸ“ Your Text: Climate change is causing more extreme weather events\n",
            "ğŸ§¼ Cleaned Version: climate change causing extreme weather event\n",
            "\n",
            "ğŸ” Prediction: ğŸŸ¢ REAL NEWS (Confidence: 65.5%)\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "\n",
            "ğŸ“ Your Text: The moon landing was filmed in a Hollywood studio\n",
            "ğŸ§¼ Cleaned Version: moon landing filmed hollywood studio\n",
            "\n",
            "ğŸ” Prediction: ğŸ”´ FAKE NEWS (Confidence: 53.6%)\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
            "\n",
            "âœ¨ Try your own news! Run: predict_news('Your news text here')\n",
            "Example: predict_news('Some breaking news story')\n"
          ]
        }
      ]
    }
  ]
}